{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Differentiation with `torch.autograd`\n",
    "In this notebook, we will explore the `torch.autograd` module in PyTorch, which provides automatic differentiation for all operations on Tensors. This is a key feature for training neural networks using backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the simplest one-layer neural network ,with input `x`, parameters `w` and `b` (weights and biases), and some loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)   # Input tensor\n",
    "y = torch.zeros(3)  # Output tensor\n",
    "\n",
    "w = torch.randn(5, 3, requires_grad =True)  # Weights\n",
    "b = torch.randn(3, requires_grad=True)  # Bias\n",
    "\n",
    "z = torch.matmul(x, w) + b  # Linear transformation\n",
    "\n",
    "# Calculate the loss\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y) # Binary Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above defines the following **Computational Graph**:\n",
    "\n",
    "![Computational Graph](./img/comp-graph.png \"Computational Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this network, `w` and `b` are *parameters*, which we need to optimize. Thus, we need to be able to compute the gradients of the loss with respect to those variables, i.e., $\\frac{\\partial L}{\\partial w}$ and $\\frac{\\partial L}{\\partial b}$. \n",
    "\n",
    "This is where `torch.autograd` comes in handy. It allows us to compute these gradients automatically using the chain rule of calculus. That is why we set the `requires_grad` property to `True` for the parameters we want to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any function that we apply to a tensor to construct a computational graph is in fact an object of class `torch.autograd.Function`. This object has two methods: `forward` and `backward`. \n",
    "1. The `forward` method computes the output of the function.\n",
    "2. The `backward` method computes the gradients of the inputs with respect to the output.\n",
    "\n",
    "A reference to the backward propagation function is stored in the `grad_fn` attribute of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for out: <AddBackward0 object at 0x7f0048631ea0>\n",
      "\n",
      "Gradient function for loss: <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f00486331f0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for out: {z.grad_fn}\\n\")\n",
    "print(f\"Gradient function for loss: {loss.grad_fn}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients\n",
    "To optimize the parameters of our model, we need to compute the derivatives of our loss function with respect to the parameters, under some fixed values of `x` and `y`. To compute those derivatives, we call `loss.backward()`, and then retrieve the values from `w.grad` and `b.grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of loss w.r.t. weights: tensor([[0.1531, 0.3012, 0.1102],\n",
      "        [0.1531, 0.3012, 0.1102],\n",
      "        [0.1531, 0.3012, 0.1102],\n",
      "        [0.1531, 0.3012, 0.1102],\n",
      "        [0.1531, 0.3012, 0.1102]])\n",
      "\n",
      "Gradient of loss w.r.t. bias: tensor([0.1531, 0.3012, 0.1102])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss.backward()  # Apply Backpropagation to compute gradients\n",
    "\n",
    "print(f\"Gradient of loss w.r.t. weights: {w.grad}\\n\")\n",
    "print(f\"Gradient of loss w.r.t. bias: {b.grad}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disabling Gradient Tracking\n",
    "By default, all tensors with `requires_grad=True` will track all operations on them. However, there are some cases when we do not need that, e.g., when we are evaluating the model on a validation or test set. In those cases, we will not backpropagate the loss so we can disable gradient tracking using `torch.no_grad()` context manager. This will reduce memory consumption for computations that would otherwise have `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x,w) + b\n",
    "print(z.requires_grad)  # Check if requires_grad is set to True\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w) + b  # No gradient tracking\n",
    "print(z.requires_grad)  # Check if requires_grad is set to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to achieve the same result is to use the `detach()` method on a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w) + b\n",
    "z_det = z.detach()  # Detach from the computation graph\n",
    "print(z_det.requires_grad)  # Check if requires_grad is set to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some reasons why you might want to disable gradient tracking:\n",
    "- Mark some parameters as *frozen parameters*.\n",
    "- Speed up computations when you are only doing forward passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and Backward Pass\n",
    "Conceptually, `autograd` keeps a record of all operations performed on tensors with `requires_grad=True` in a directed acyclic graph (DAG) consisting of `Function` objects. In this DAG, leaves are the input tensors and roots are the output tensors. By tracing this graph from roots to leaves, you can automatically compute the gradients using the chain rule.\n",
    "\n",
    "#### In a forward pass, `autograd` does 2 things:\n",
    "- Run the requested operation to compute a resulting tensor.\n",
    "- Maintain the operation's gradient function in the *DAG*.\n",
    "  - Store the context needed for computing the gradients in the `grad_fn` attribute of the resulting tensor.\n",
    "\n",
    "#### In a backward pass, `backward()` then:\n",
    "- Computes the gradients from each `.grad_fn` in the *DAG*.\n",
    "- Accumulates them in the respective tensor's `.grad` attribute.\n",
    "- Using the chain rule, Propagates all the way back to the leaves of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Gradients and Jacobian Product\n",
    "In many cases, we have a scalar loss function, and we need to compute the gradient with respect to the parameters. Howver, there are cases when the network's output is an arbitrary tensor. In this case, `PyTorch` allows computing the *Jacobian Product*.\n",
    "\n",
    "For a vector output $y = f(x)$, where $x=(x_1, ..., x_n)$ and $y=(y_1, ..., y_m)$, a gradient of $y$ with respect to $x (\\frac{\\partial y}{\\partial x})$ is given by the Jacobian matrix $J$ of the function $f$:\n",
    "$$\n",
    "J = \\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x_1} & \\cdots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial y_m}{\\partial x_1} & \\cdots & \\frac{\\partial y_m}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of computing the full Jacobian matrix, we can compute the product of the Jacobian with a vector $v$ using `torch.autograd.functional.jacobian`. This is useful when we only need the gradient of the output with respect to a small number of inputs, or when the Jacobian is too large to compute explicitly.\n",
    "\n",
    "This is achieved by calling `backward()` on the output tensor with $v$ as an argument. The size of $v$ must match the size of the original output tensor. \n",
    "\n",
    "Jacobian Product = $v^T \\cdot J$. By selecting an appropriate $v$ we can compute the gradient of the desired parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]], requires_grad=True)\n",
      "\n",
      "out: tensor([[4., 1., 1., 1.],\n",
      "        [1., 4., 1., 1.],\n",
      "        [1., 1., 4., 1.],\n",
      "        [1., 1., 1., 4.],\n",
      "        [1., 1., 1., 1.]], grad_fn=<TBackward0>)\n",
      "\n",
      "Gradient function for out: <TBackward0 object at 0x7f0048633310>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp = torch.eye(4, 5, requires_grad=True)  # Input tensor\n",
    "out = (inp+1).pow(2).t()\n",
    "\n",
    "print(f\"inp: {inp}\\n\")\n",
    "print(f\"out: {out}\\n\")\n",
    "print(f\"Gradient function for out: {out.grad_fn}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Call\n",
      "Gradient of out w.r.t. inp: tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n",
      "\n",
      "Second Call\n",
      "Gradient of out w.r.t. inp after second backward: tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.]])\n",
      "\n",
      "Third Call\n",
      "Gradient of out w.r.t. inp after clearing gradient: tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform backpropagation on the output tensor\n",
    "out.backward(torch.ones_like(out), retain_graph=True)  # Retain the graph for further backward calls\n",
    "print(f\"First Call\\nGradient of out w.r.t. inp: {inp.grad}\\n\")\n",
    "out.backward(torch.ones_like(out), retain_graph=True)  # Perform backpropagation again\n",
    "print(f\"Second Call\\nGradient of out w.r.t. inp after second backward: {inp.grad}\\n\")\n",
    "\n",
    "# Clear the gradient\n",
    "inp.grad.zero_() \n",
    "# Perform another backward pass\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"Third Call\\nGradient of out w.r.t. inp after clearing gradient: {inp.grad}\\n\")\n",
    "\n",
    "# Clear the gradient\n",
    "inp.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
